{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On dynamic range: 'roundoff errors' and the FFT\n",
    "\n",
    "### Background\n",
    "Accuracy of the FFT has been a consideration since (at least) the initial implementation of the Cooley-Tukey algorithm, there are a handful papers on the subject going right back to the 60's - 'accuracy' and 'round-off error' being the most relevant search terms. The best recent references I could find are:\n",
    "\n",
    "* [Accuracy of the Discrete Fourier Transform and the Fast Fourier Transform (Schatzman 1996)](https://doi.org/10.1137/S1064827593247023) - a relatively recent review of the theory\n",
    "\n",
    "* [Implementing FFTs in Practice (Johnson et al. 2008)](http://cnx.org/content/m16336/) - from the authors of FFTW\n",
    "\n",
    "The consensus seems to be that the relative error from a (carefully implemented and tuned) FFT of input length N grows as $O(\\log{N})$ in the worst case, and $O(\\sqrt{\\log{N}})$ on average for the more amenable case of random input data. This applies to one-dimensional FFT's, but (perhaps surprisingly) the error-growth curve for a 2-dimensional FFT is likely of the same order and with a scaling constant only marginally larger (cf $\\S6$, Schatzman 1996).\n",
    "\n",
    "\n",
    "However, it's worth noting that the typical results (as reported in the [FFTW accuracy benchmarks](http://www.fftw.org/accuracy/comments.html)) are obtained by testing with random data (computed with arbitrarily high precision and then compare with results computed via standard single / double floating precision). So when considering a radio-field with a bright source and a faint source, we may be in the 'worst-case' regime. On the other hand, if we are recovering a weak signal from many noisy visibilities then we very close to emulating the 'typical' random-noise regime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a typical benchmark plot for FFTW:\n",
    "![Illustrative FFTW benchmark plot](http://www.fftw.org/accuracy/Ryzen-7-3.6GHz/ryzen.1d.scxx.acc.p2.png)\n",
    "\n",
    "This has a similar shape to the best-case curves from Schatzman 1996 (cf $\\S3.4$).\n",
    "For an FFT of length $N$ we expect a relative error in the random-noise 'typical' cose of order $$\\sqrt{\\log{N}}\\epsilon = 3\\epsilon$$\n",
    "where $\\epsilon$ is the machine accuracy --- recall this is  $\\frac{1}{2^{24}}$ in the single-precision case.\n",
    "So we can run a quick calculation, generate our own plot, and check if the FFTW plot agrees with our understanding of the theory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "import numpy as np\n",
    "from matplotlib.ticker import LogLocator\n",
    "\n",
    "\n",
    "N = np.asarray([float(2**i) for i in range(4,18)])\n",
    "epsilon = 1./ 2**26\n",
    "arbitrary_scaling_factor = 0.6 # cf Schatzman 1996, error function 3b\n",
    "\n",
    "def fft_err_factor_for_random_inputs(N):\n",
    "    return arbitrary_scaling_factor* np.sqrt(np.log2(N))\n",
    "\n",
    "def fft_err_factor_worst_case(N):\n",
    "    return  np.log2(N)#  worst case\n",
    "\n",
    "plt.plot(N, \n",
    "         fft_err_factor_for_random_inputs(N), \n",
    "#          fft_err_factor_for_random_inputs(N)*epsilon,\n",
    "         label='Typical case (random inputs)')\n",
    "\n",
    "plt.plot(N, fft_err_factor_worst_case(N), label='Worst case')\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xscale('log', basex=2)\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "plt.xlim(min(N), max(N))\n",
    "# plt.axhline(1e-7, ls=':')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Relative error')\n",
    "plt.axvline(1024, ls=':', label='N=1024')\n",
    "\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result - not a perfect agreement, but the 'typical case' plot is in the right ballpark (hard to judge exactly without a better idea of the scaling on the FFT benchmark plot).\n",
    "\n",
    "So if things are good, relative precision due to the FFT is only a factor of ~2 worse than in any other mathematical operation - we lose about 1 bit of precision - and that's pretty flat.\n",
    "\n",
    "If we hit the worst case, then we lose about a factor of 10 for N=2^10=1024 - or about 3-4 bits of precision depending on the size of our transform, for a typical transform size of $2^8$ -  $2^{16}$ (256 - 65536).\n",
    "\n",
    "## Test-case 1: Bright and faint sources, no noise.\n",
    "\n",
    "So, let's see if things behave as expected in the 1-d case. We'll start with a bright source and faint source (modelled by single non-zero pixels), then perform the FFT to get our 1-d 'visibilities', then drop to single-precision and see if the faint source gets lost to roundoff error.\n",
    "\n",
    "Note that numpy only implements double precision FFTs, so we switch to the SciPy [implementation](https://docs.scipy.org/doc/scipy/reference/fftpack.html) which also has a single-precision option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.fftpack as fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2**12\n",
    "bright_src_flux = 1.\n",
    "faint_src_flux = bright_src_flux / 2**30\n",
    "input_data = np.zeros(N, dtype=np.complex128) \n",
    "bright_src_idx  = int(N/2 + N/3 + 7)\n",
    "faint_src_idx = int(N/2 + N/4 +5)\n",
    "\n",
    "bright_src_region = slice(bright_src_idx-10, bright_src_idx+10)\n",
    "faint_src_region = slice(faint_src_idx-10, faint_src_idx+10)\n",
    "\n",
    "input_data[bright_src_idx] = bright_src_flux\n",
    "input_data[faint_src_idx] = faint_src_flux\n",
    "\n",
    "input_idx = np.arange(N)\n",
    "for idx in input_data.nonzero()[0]:\n",
    "    print(idx, input_data[idx])\n",
    "input_nz_idx = input_data.nonzero()\n",
    "\n",
    "# plt.scatter(input_idx[input_nz_idx], input_data[input_nz_idx])\n",
    "plt.plot(input_data[faint_src_region])\n",
    "plt.xlabel('Pixel index')\n",
    "plt.ylabel('Component value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = fftpack.fft(input_data)\n",
    "seed = 42\n",
    "rstate = np.random.RandomState(seed)\n",
    "noise = rstate.normal(loc=0, scale=faint_src_flux*(np.sqrt(N)/(8.)), size=(len(vis), 2))\n",
    "noisy_vis = vis + (noise[:, 0] + 1j * noise[:, 1])\n",
    "\n",
    "vis_f = np.asarray(vis, dtype=np.complex64)\n",
    "noisy_vis_f = np.asarray(noisy_vis, dtype=np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = fftpack.ifft(vis)\n",
    "output_f = fftpack.ifft(vis_f)\n",
    "noisy_output = fftpack.ifft(noisy_vis)\n",
    "noisy_output_f = fftpack.ifft(noisy_vis_f)\n",
    "print(output.dtype)\n",
    "# for idx in output.nonzero()[0]:\n",
    "#     print(idx, output[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(input_idx[faint_src_region],np.real(output[faint_src_region]), label='Double prec.')\n",
    "ax.plot(input_idx[faint_src_region],np.real(output_f[faint_src_region]), label='Single prec.')\n",
    "\n",
    "# plt.yscale('log')\n",
    "ax.set_xlabel('Pixel index')\n",
    "ax.set_ylabel('Component value')\n",
    "ax.axvline(faint_src_idx, ls=':')\n",
    "ax.axhline(faint_src_flux, ls=':')\n",
    "# ax.set_ylim( -faint_src_flux, 2*faint_src_flux)\n",
    "ax.set_title('Faint source region')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.scatter(input_idx[bright_src_region],np.real(output[bright_src_region]))\n",
    "ax.axvline(bright_src_idx, ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
